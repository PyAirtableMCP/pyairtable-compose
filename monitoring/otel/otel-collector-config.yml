# OpenTelemetry Collector Configuration
# Comprehensive telemetry data collection and processing for PyAirtable Platform

receivers:
  # OTLP receiver for application traces and metrics
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318
        cors:
          allowed_origins:
            - "http://localhost:3000"
            - "http://frontend:3000"
            - "http://api-gateway:8000"

  # Prometheus receiver for scraping existing metrics
  prometheus:
    config:
      scrape_configs:
        - job_name: 'otel-collector'
          scrape_interval: 30s
          static_configs:
            - targets: ['localhost:8888']

  # Jaeger receiver for legacy Jaeger traces
  jaeger:
    protocols:
      grpc:
        endpoint: 0.0.0.0:14250
      thrift_http:
        endpoint: 0.0.0.0:14268

  # Host metrics receiver for system monitoring
  hostmetrics:
    collection_interval: 30s
    scrapers:
      cpu:
        metrics:
          system.cpu.utilization:
            enabled: true
      memory:
        metrics:
          system.memory.utilization:
            enabled: true
      disk:
        metrics:
          system.disk.io.time:
            enabled: true
      network:
        metrics:
          system.network.io:
            enabled: true
      filesystem:
        metrics:
          system.filesystem.utilization:
            enabled: true

  # Docker stats receiver for container metrics
  docker_stats:
    endpoint: unix:///var/run/docker.sock
    collection_interval: 30s
    timeout: 20s
    api_version: 1.24
    metrics:
      container.cpu.usage.total:
        enabled: true
      container.memory.usage.limit:
        enabled: true
      container.network.io.usage.rx_bytes:
        enabled: true
      container.network.io.usage.tx_bytes:
        enabled: true

processors:
  # Batch processor for efficient data handling
  batch:
    timeout: 1s
    send_batch_size: 1024
    send_batch_max_size: 2048

  # Memory limiter to prevent OOM
  memory_limiter:
    check_interval: 1s
    limit_mib: 256

  # Resource processor to add consistent labels
  resource:
    attributes:
      - key: service.cluster
        value: "pyairtable-platform"
        action: upsert
      - key: service.environment
        from_attribute: deployment.environment
        action: insert
      - key: service.version
        from_attribute: service.version
        action: insert

  # Attributes processor for trace enhancement
  attributes:
    actions:
      # Add platform-specific attributes
      - key: platform.name
        value: "pyairtable"
        action: insert
      - key: platform.tier
        from_attribute: service.tier
        action: insert
      
      # Sanitize sensitive data
      - key: http.request.header.authorization
        action: delete
      - key: http.request.header.x-api-key
        action: delete
      - key: db.statement
        action: update
        from_attribute: db.statement
        # Mask sensitive SQL data
        value: "SELECT ... FROM ..."

  # Probabilistic sampler for cost optimization
  probabilistic_sampler:
    sampling_percentage: 10.0  # Sample 10% of traces

  # Tail sampling for intelligent trace selection
  tail_sampling:
    decision_wait: 10s
    num_traces: 50000
    expected_new_traces_per_sec: 100
    policies:
      # Always sample error traces
      - name: error-traces
        type: status_code
        status_code:
          status_codes: [ ERROR ]
      # Sample slow traces (>2s)
      - name: slow-traces
        type: latency
        latency:
          threshold_ms: 2000
      # Sample traces with specific services
      - name: critical-services
        type: string_attribute
        string_attribute:
          key: service.name
          values:
            - api-gateway
            - platform-services
            - llm-orchestrator
      # Probabilistic sampling for others
      - name: probabilistic-policy
        type: probabilistic
        probabilistic:
          sampling_percentage: 5

  # Span processor for trace enhancement
  span:
    name:
      # Normalize span names
      to_attributes:
        rules:
          - pattern: ^(GET|POST|PUT|DELETE|PATCH)\s+(.*)$
            name_pattern: "$1 $2"

exporters:
  # Jaeger exporter for distributed tracing
  jaeger:
    endpoint: jaeger-all-in-one:14250
    tls:
      insecure: true

  # Prometheus exporter for metrics
  prometheus:
    endpoint: "0.0.0.0:8889"
    const_labels:
      cluster: "pyairtable-platform"
    
  # OTLP exporter for external observability platforms
  # otlp/datadog:
  #   endpoint: "https://api.datadoghq.com"
  #   headers:
  #     DD-API-KEY: "${DATADOG_API_KEY}"

  # otlp/newrelic:
  #   endpoint: "https://otlp.nr-data.net:4317"
  #   headers:
  #     api-key: "${NEW_RELIC_LICENSE_KEY}"

  # Logging exporter for debugging
  logging:
    loglevel: info
    sampling_initial: 5
    sampling_thereafter: 200

  # File exporter for local analysis
  file:
    path: /tmp/traces.json
    rotation:
      max_megabytes: 100
      max_days: 3
      max_backups: 3

extensions:
  # Health check extension
  health_check:
    endpoint: 0.0.0.0:13133
    
  # pprof extension for performance profiling
  pprof:
    endpoint: 0.0.0.0:1777
    
  # zpages extension for diagnostics
  zpages:
    endpoint: 0.0.0.0:55679

service:
  extensions: [health_check, pprof, zpages]
  
  pipelines:
    # Traces pipeline
    traces:
      receivers: [otlp, jaeger]
      processors: [
        memory_limiter,
        resource,
        attributes,
        tail_sampling,
        span,
        batch
      ]
      exporters: [jaeger, logging]

    # Metrics pipeline
    metrics:
      receivers: [otlp, prometheus, hostmetrics, docker_stats]
      processors: [
        memory_limiter,
        resource,
        batch
      ]
      exporters: [prometheus, logging]

    # Logs pipeline (if enabled)
    logs:
      receivers: [otlp]
      processors: [
        memory_limiter,
        resource,
        batch
      ]
      exporters: [logging]

  # Telemetry configuration
  telemetry:
    logs:
      level: "info"
    metrics:
      address: 0.0.0.0:8888
      level: detailed
    traces:
      processors: [batch]