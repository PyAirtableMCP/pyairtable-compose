# Filebeat Configuration for PyAirtable Platform
# Comprehensive log shipping from Docker containers to ELK stack

filebeat.inputs:
  # Docker container logs
  - type: container
    paths:
      - '/var/lib/docker/containers/*/*.log'
    
    # Processor to parse Docker JSON logs
    processors:
      - add_docker_metadata:
          host: "unix:///var/run/docker.sock"
      
      # Add Kubernetes metadata if running in K8s
      - add_kubernetes_metadata:
          host: ${NODE_NAME}
          matchers:
          - logs_path:
              logs_path: "/var/log/containers/"
      
      # Parse JSON logs from applications
      - decode_json_fields:
          fields: ["message"]
          target: ""
          overwrite_keys: true
          add_error_key: true
      
      # Add timestamp parsing
      - timestamp:
          field: time
          layouts:
            - '2006-01-02T15:04:05.000000000Z'
            - '2006-01-02T15:04:05Z'
            - '2006-01-02 15:04:05'
          test:
            - '2023-10-01T12:34:56.789Z'
      
      # Add service name based on container name
      - script:
          lang: javascript
          id: service_name_processor
          source: >
            function process(event) {
              var containerName = event.Get("container.name");
              if (containerName) {
                // Extract service name from container name
                var serviceName = containerName.replace(/^\//, '').replace(/-[0-9]+$/, '');
                event.Put("service.name", serviceName);
                
                // Set service tier based on service name
                var tier = "application";
                if (serviceName.includes("postgres") || serviceName.includes("redis") || serviceName.includes("elasticsearch")) {
                  tier = "infrastructure";
                } else if (serviceName.includes("prometheus") || serviceName.includes("grafana") || serviceName.includes("jaeger")) {
                  tier = "observability";
                } else if (serviceName.includes("api-gateway")) {
                  tier = "gateway";
                } else if (serviceName.includes("llm") || serviceName.includes("ai")) {
                  tier = "ai-ml";
                }
                event.Put("service.tier", tier);
                
                // Add cost center for billing
                event.Put("cost.center", tier);
              }
            }
      
      # Add environment information
      - add_fields:
          target: deployment
          fields:
            environment: ${ENVIRONMENT:development}
            cluster: pyairtable-platform
            platform: pyairtable
      
      # Drop health check and metrics logs to reduce noise
      - drop_event:
          when:
            or:
              - contains:
                  message: "GET /health"
              - contains:
                  message: "GET /metrics"
              - contains:
                  message: "GET /ready"
              - contains:
                  message: "healthcheck"

    # Multiline pattern for stack traces
    multiline:
      pattern: '^[[:space:]]+(at|\.\.\.|\t|Caused by:|	)'
      negate: false
      match: after
      max_lines: 500
      timeout: 5s

    # Field filtering
    fields:
      log_type: container
      data_stream: logs
    fields_under_root: true

    # Include/exclude specific containers
    include_lines: ['ERROR', 'WARN', 'INFO', 'DEBUG', 'TRACE']
    exclude_lines: ['^$']  # Empty lines

  # Application-specific log files (if mounted)
  - type: log
    paths:
      - '/app/logs/*.log'
      - '/var/log/app/*.log'
    
    # JSON log parsing
    processors:
      - decode_json_fields:
          fields: ["message"]
          target: ""
          overwrite_keys: true
    
    fields:
      log_type: application
      data_stream: logs
    fields_under_root: true

# Processors for all inputs
processors:
  # Add host information
  - add_host_metadata:
      when.not.contains.tags: forwarded
      
  # Add process information
  - add_process_metadata:
      match_pids: ['process.pid', 'process.parent.pid']
      
  # Fingerprint for deduplication
  - fingerprint:
      fields: ["message", "service.name", "@timestamp"]
      target_field: "@metadata.fingerprint"
      
  # Rate limiting to prevent log flooding
  - rate_limit:
      limit: "10000/s"
      fields: ["service.name"]

# Output to Logstash
output.logstash:
  hosts: ["logstash:5044"]
  
  # Load balancing
  loadbalance: true
  
  # Compression
  compression_level: 3
  
  # SSL/TLS (if enabled)
  # ssl:
  #   enabled: true
  #   certificate_authorities: ["/etc/filebeat/certs/ca.crt"]
  #   certificate: "/etc/filebeat/certs/client.crt"
  #   key: "/etc/filebeat/certs/client.key"

# Alternative: Direct to Elasticsearch
# output.elasticsearch:
#   hosts: ["elasticsearch:9200"]
#   index: "pyairtable-logs-%{+yyyy.MM.dd}"
#   template.name: "pyairtable"
#   template.pattern: "pyairtable-*"

# Logging configuration
logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644

# Monitoring
monitoring:
  enabled: true
  elasticsearch:
    hosts: ["elasticsearch:9200"]
    index: "filebeat-monitoring"

# Performance settings
queue:
  mem:
    events: 4096
    flush.min_events: 512
    flush.timeout: 1s

# HTTP endpoint for health checks
http:
  enabled: true
  host: 0.0.0.0
  port: 5066

# Filebeat modules (optional)
filebeat.config.modules:
  path: ${path.config}/modules.d/*.yml
  reload.enabled: false

# Template configuration
setup.template:
  enabled: true
  name: "pyairtable-logs"
  pattern: "pyairtable-logs-*"
  settings:
    index:
      number_of_shards: 1
      number_of_replicas: 0
      codec: best_compression
      refresh_interval: "5s"
      
# ILM (Index Lifecycle Management)
setup.ilm:
  enabled: true
  rollover_alias: "pyairtable-logs"
  pattern: "{now/d}-000001"
  policy: |
    {
      "policy": {
        "phases": {
          "hot": {
            "actions": {
              "rollover": {
                "max_size": "1GB",
                "max_age": "1d"
              }
            }
          },
          "warm": {
            "min_age": "7d",
            "actions": {
              "allocate": {
                "number_of_replicas": 0
              }
            }
          },
          "cold": {
            "min_age": "30d",
            "actions": {
              "allocate": {
                "number_of_replicas": 0
              }
            }
          },
          "delete": {
            "min_age": "90d"
          }
        }
      }
    }