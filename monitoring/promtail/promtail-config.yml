# Promtail Configuration for PyAirtable Platform
# Collects logs from all Docker containers and sends to Loki

server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  # === APPLICATION SERVICES LOGS ===
  - job_name: pyairtable-services
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
    
    relabel_configs:
      # Only collect logs from PyAirtable services
      - source_labels: ['__meta_docker_container_name']
        regex: '/(api-gateway|llm-orchestrator|mcp-server|airtable-gateway|platform-services|automation-services|saga-orchestrator|frontend)'
        action: keep
      
      # Add service label
      - source_labels: ['__meta_docker_container_name']
        regex: '/(.+)'
        target_label: 'service'
        replacement: '${1}'
      
      # Add tier labels for cost tracking
      - source_labels: ['service']
        regex: 'api-gateway'
        target_label: 'tier'
        replacement: 'gateway'
      
      - source_labels: ['service']
        regex: 'llm-orchestrator'
        target_label: 'tier'
        replacement: 'ai-ml'
      
      - source_labels: ['service']
        regex: '(mcp-server)'
        target_label: 'tier'
        replacement: 'protocol'
      
      - source_labels: ['service']
        regex: 'airtable-gateway'
        target_label: 'tier'
        replacement: 'integration'
      
      - source_labels: ['service']
        regex: 'platform-services'
        target_label: 'tier'
        replacement: 'platform'
      
      - source_labels: ['service']
        regex: 'automation-services'
        target_label: 'tier'
        replacement: 'automation'
      
      - source_labels: ['service']
        regex: 'saga-orchestrator'
        target_label: 'tier'
        replacement: 'orchestration'
      
      - source_labels: ['service']
        regex: 'frontend'
        target_label: 'tier'
        replacement: 'frontend'
      
      # Add environment
      - target_label: 'environment'
        replacement: 'development'
      
      # Add cost center for AI services
      - source_labels: ['tier']
        regex: 'ai-ml'
        target_label: 'cost_center'
        replacement: 'ai-compute'

    pipeline_stages:
      # Parse JSON logs
      - json:
          expressions:
            level: level
            timestamp: timestamp
            message: message
            service: service
            trace_id: trace_id
            span_id: span_id
      
      # Add timestamp
      - timestamp:
          source: timestamp
          format: RFC3339
      
      # Extract log level
      - labels:
          level:
      
      # Parse application-specific logs
      - match:
          selector: '{service="llm-orchestrator"}'
          stages:
            - json:
                expressions:
                  model: model
                  tokens_used: tokens_used
                  cost: cost
                  request_type: request_type
            - labels:
                model:
                request_type:
      
      - match:
          selector: '{service="api-gateway"}'
          stages:
            - json:
                expressions:
                  method: method
                  path: path
                  status_code: status_code
                  response_time: response_time
            - labels:
                method:
                status_code:
      
      # Rate limiting for cost control
      - limit:
          rate: 100
          burst: 150
          drop: true

  # === INFRASTRUCTURE LOGS ===
  - job_name: infrastructure
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
    
    relabel_configs:
      # Only collect logs from infrastructure services
      - source_labels: ['__meta_docker_container_name']
        regex: '/(postgres|redis|prometheus|grafana|jaeger|loki|alertmanager)'
        action: keep
      
      - source_labels: ['__meta_docker_container_name']
        regex: '/(.+)'
        target_label: 'service'
        replacement: '${1}'
      
      - target_label: 'tier'
        replacement: 'infrastructure'
      
      - target_label: 'environment'
        replacement: 'development'

    pipeline_stages:
      # Basic parsing for infrastructure logs
      - regex:
          expression: '(?P<timestamp>\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.\d+Z)\s+(?P<level>\w+)\s+(?P<component>\w+)\s+(?P<message>.*)'
      
      - labels:
          level:
          component:
      
      - timestamp:
          source: timestamp
          format: RFC3339
      
      # Rate limiting
      - limit:
          rate: 50
          burst: 100
          drop: true

  # === ERROR AND CRITICAL LOGS ===
  - job_name: critical-logs
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
    
    relabel_configs:
      # Collect from all PyAirtable containers
      - source_labels: ['__meta_docker_container_name']
        regex: '/(api-gateway|llm-orchestrator|mcp-server|airtable-gateway|platform-services|automation-services|saga-orchestrator|frontend)'
        action: keep
      
      - source_labels: ['__meta_docker_container_name']
        regex: '/(.+)'
        target_label: 'service'
        replacement: '${1}'
      
      - target_label: 'environment'
        replacement: 'development'

    pipeline_stages:
      # Only keep ERROR and CRITICAL logs
      - match:
          selector: '{level!~"ERROR|CRITICAL|FATAL"}'
          action: drop
      
      # Enhanced parsing for critical logs
      - json:
          expressions:
            level: level
            message: message
            error: error
            stack_trace: stack_trace
            user_id: user_id
            request_id: request_id
      
      - labels:
          level:
      
      # No rate limiting for critical logs
      - limit:
          rate: 1000
          burst: 2000