name: PyAirtable MCP - Sprint 1 CI/CD Pipeline

on:
  push:
    branches: [ main, develop, 'feature/*' ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:
    inputs:
      deployment_target:
        description: 'Deployment target'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production

env:
  REGISTRY: ghcr.io
  PROJECT_NAME: pyairtable
  NODE_VERSION: '20'
  PYTHON_VERSION: '3.11'
  GO_VERSION: '1.21'

jobs:
  # Security and Vulnerability Scanning
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results to GitHub Security tab
        uses: github/codeql-action/upload-sarif@v2
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

  # Test Suite - Services
  test-services:
    name: Test Microservices
    runs-on: ubuntu-latest
    strategy:
      matrix:
        service: [api-gateway, llm-orchestrator, mcp-server, airtable-gateway, platform-services, automation-services, saga-orchestrator]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Set up Go
        uses: actions/setup-go@v4
        with:
          go-version: ${{ env.GO_VERSION }}

      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: |
            ~/.cache/pip
            ~/go/pkg/mod
            ~/.npm
          key: ${{ runner.os }}-deps-${{ hashFiles('**/requirements.txt', '**/go.mod', '**/package-lock.json') }}

      - name: Install dependencies
        run: |
          if [ -f "${{ matrix.service }}/requirements.txt" ]; then
            pip install -r ${{ matrix.service }}/requirements.txt
            pip install pytest pytest-cov pytest-asyncio
          fi
          
          if [ -f "${{ matrix.service }}/go.mod" ]; then
            cd ${{ matrix.service }}
            go mod download
            cd ..
          fi

      - name: Run unit tests
        run: |
          if [ -f "${{ matrix.service }}/tests/" ]; then
            cd ${{ matrix.service }}
            pytest tests/ --cov=src --cov-report=xml --cov-report=term-missing
          fi
          
          if [ -f "${{ matrix.service }}/main_test.go" ]; then
            cd ${{ matrix.service }}
            go test -v -race -coverprofile=coverage.out ./...
          fi

      - name: Upload coverage reports
        uses: codecov/codecov-action@v3
        with:
          file: ./${{ matrix.service }}/coverage.xml
          flags: ${{ matrix.service }}

  # Test Suite - Frontend
  test-frontend:
    name: Test Frontend
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./frontend-services/tenant-dashboard

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: './frontend-services/tenant-dashboard/package-lock.json'

      - name: Install dependencies
        run: npm ci

      - name: Run linting
        run: npm run lint

      - name: Run type checking
        run: npm run type-check

      - name: Run unit tests
        run: npm run test:ci

      - name: Build application
        run: npm run build

      - name: Upload build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: frontend-build
          path: ./frontend-services/tenant-dashboard/.next

  # Docker Build and Push
  build-and-push:
    name: Build and Push Docker Images
    runs-on: ubuntu-latest
    needs: [security-scan, test-services, test-frontend]
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop')
    
    strategy:
      matrix:
        service: 
          - api-gateway
          - llm-orchestrator  
          - mcp-server
          - airtable-gateway
          - platform-services
          - automation-services
          - saga-orchestrator
          - frontend

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ github.repository_owner }}/${{ env.PROJECT_NAME }}-${{ matrix.service }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: ./${{ matrix.service }}
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64,linux/arm64

  # Integration Testing
  integration-test:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [build-and-push]
    if: github.ref == 'refs/heads/develop' || github.event_name == 'pull_request'
    
    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_USER: test_user
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup test environment
        run: |
          cp .env.example .env.test
          echo "POSTGRES_USER=test_user" >> .env.test
          echo "POSTGRES_PASSWORD=test_password" >> .env.test
          echo "POSTGRES_DB=test_db" >> .env.test
          echo "REDIS_PASSWORD=" >> .env.test
          echo "API_KEY=test-api-key" >> .env.test

      - name: Start services
        run: |
          docker-compose -f docker-compose.sprint1.yml --env-file .env.test up -d --wait
          sleep 30

      - name: Run integration tests
        run: |
          python -m pytest integration_tests/ -v --tb=short
          
          # API endpoint tests
          curl -f http://localhost:8000/api/health || exit 1
          curl -f http://localhost:8002/health || exit 1
          curl -f http://localhost:8001/health || exit 1
          curl -f http://localhost:8003/health || exit 1
          curl -f http://localhost:8007/health || exit 1

      - name: Check service logs on failure
        if: failure()
        run: |
          docker-compose -f docker-compose.sprint1.yml --env-file .env.test logs

      - name: Cleanup
        if: always()
        run: |
          docker-compose -f docker-compose.sprint1.yml --env-file .env.test down -v

  # Performance Testing
  performance-test:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: [integration-test]
    if: github.ref == 'refs/heads/develop'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup K6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Setup test environment
        run: |
          cp .env.example .env.perf
          docker-compose -f docker-compose.sprint1.yml --env-file .env.perf up -d --wait
          sleep 60

      - name: Run load tests
        run: |
          k6 run --out json=performance-results.json performance-testing/simple-load-test.js

      - name: Upload performance results
        uses: actions/upload-artifact@v3
        with:
          name: performance-results
          path: performance-results.json

      - name: Cleanup
        if: always()
        run: |
          docker-compose -f docker-compose.sprint1.yml --env-file .env.perf down -v

  # Staging Deployment
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [performance-test]
    if: github.ref == 'refs/heads/develop' || (github.event_name == 'workflow_dispatch' && github.event.inputs.deployment_target == 'staging')
    environment: staging

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0

      - name: Deploy infrastructure
        working-directory: ./infrastructure
        run: |
          terraform init
          terraform workspace select staging || terraform workspace new staging
          terraform plan -var="environment=staging" -out=staging.tfplan
          terraform apply staging.tfplan

      - name: Update ECS services
        run: |
          aws ecs update-service --cluster pyairtable-staging --service api-gateway --force-new-deployment
          aws ecs update-service --cluster pyairtable-staging --service llm-orchestrator --force-new-deployment
          aws ecs update-service --cluster pyairtable-staging --service mcp-server --force-new-deployment
          aws ecs update-service --cluster pyairtable-staging --service airtable-gateway --force-new-deployment
          aws ecs update-service --cluster pyairtable-staging --service platform-services --force-new-deployment

      - name: Wait for deployment
        run: |
          aws ecs wait services-stable --cluster pyairtable-staging --services api-gateway llm-orchestrator mcp-server airtable-gateway platform-services

      - name: Run smoke tests
        run: |
          STAGING_URL=$(aws elbv2 describe-load-balancers --names pyairtable-staging-alb --query 'LoadBalancers[0].DNSName' --output text)
          curl -f "http://${STAGING_URL}/api/health" || exit 1
          
      - name: Notify deployment success
        uses: 8398a7/action-slack@v3
        with:
          status: custom
          custom_payload: |
            {
              "text": "âœ… PyAirtable staging deployment successful",
              "attachments": [{
                "color": "good",
                "fields": [{
                  "title": "Environment",
                  "value": "staging",
                  "short": true
                }, {
                  "title": "Commit",
                  "value": "${{ github.sha }}",
                  "short": true
                }]
              }]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

  # Production Deployment
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [deploy-staging]
    if: github.ref == 'refs/heads/main' || (github.event_name == 'workflow_dispatch' && github.event.inputs.deployment_target == 'production')
    environment: production

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0

      - name: Deploy infrastructure
        working-directory: ./infrastructure
        run: |
          terraform init
          terraform workspace select prod || terraform workspace new prod
          terraform plan -var="environment=prod" -out=prod.tfplan
          terraform apply prod.tfplan

      - name: Blue-Green deployment
        run: |
          # Implement blue-green deployment logic
          aws ecs update-service --cluster pyairtable-prod --service api-gateway --force-new-deployment
          aws ecs wait services-stable --cluster pyairtable-prod --services api-gateway
          
          # Health check before proceeding
          PROD_URL=$(aws elbv2 describe-load-balancers --names pyairtable-prod-alb --query 'LoadBalancers[0].DNSName' --output text)
          curl -f "http://${PROD_URL}/api/health" || exit 1
          
          # Continue with other services
          aws ecs update-service --cluster pyairtable-prod --service llm-orchestrator --force-new-deployment
          aws ecs update-service --cluster pyairtable-prod --service mcp-server --force-new-deployment
          aws ecs update-service --cluster pyairtable-prod --service airtable-gateway --force-new-deployment
          aws ecs update-service --cluster pyairtable-prod --service platform-services --force-new-deployment

      - name: Wait for deployment
        run: |
          aws ecs wait services-stable --cluster pyairtable-prod --services api-gateway llm-orchestrator mcp-server airtable-gateway platform-services

      - name: Post-deployment tests
        run: |
          PROD_URL=$(aws elbv2 describe-load-balancers --names pyairtable-prod-alb --query 'LoadBalancers[0].DNSName' --output text)
          curl -f "http://${PROD_URL}/api/health" || exit 1

      - name: Notify deployment success
        uses: 8398a7/action-slack@v3
        with:
          status: custom
          custom_payload: |
            {
              "text": "ðŸš€ PyAirtable production deployment successful",
              "attachments": [{
                "color": "good",
                "fields": [{
                  "title": "Environment", 
                  "value": "production",
                  "short": true
                }, {
                  "title": "Commit",
                  "value": "${{ github.sha }}",
                  "short": true
                }]
              }]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}