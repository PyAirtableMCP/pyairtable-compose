name: Blue/Green Application Deployment

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: true
        type: choice
        options:
          - staging
          - production
      image_tag:
        description: 'Container image tag to deploy'
        required: true
        type: string
      deployment_type:
        description: 'Deployment strategy'
        required: true
        default: 'blue-green'
        type: choice
        options:
          - blue-green
          - canary
          - rolling
      rollback:
        description: 'Rollback to previous version'
        required: false
        default: false
        type: boolean

env:
  AWS_REGION: "us-west-2"
  KUBECTL_VERSION: "1.28.0"
  HELM_VERSION: "3.13.0"
  
jobs:
  pre-deployment-checks:
    name: Pre-deployment Checks
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment }}
    
    outputs:
      cluster-name: ${{ steps.cluster-info.outputs.cluster-name }}
      current-color: ${{ steps.current-deployment.outputs.current-color }}
      target-color: ${{ steps.current-deployment.outputs.target-color }}
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
          role-to-assume: ${{ secrets.AWS_DEPLOYMENT_ROLE_ARN }}
          role-duration-seconds: 3600

      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: ${{ env.KUBECTL_VERSION }}

      - name: Setup Helm
        uses: azure/setup-helm@v3
        with:
          version: ${{ env.HELM_VERSION }}

      - name: Get cluster info
        id: cluster-info
        run: |
          CLUSTER_NAME="pyairtable-${{ inputs.environment }}-eks"
          echo "cluster-name=$CLUSTER_NAME" >> $GITHUB_OUTPUT
          
          # Update kubeconfig
          aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name $CLUSTER_NAME

      - name: Verify cluster connectivity
        run: |
          kubectl cluster-info
          kubectl get nodes
          
      - name: Check current deployment
        id: current-deployment
        run: |
          # Check which color is currently active
          CURRENT_COLOR=$(kubectl get service pyairtable-app-service -o jsonpath='{.spec.selector.color}' 2>/dev/null || echo "blue")
          TARGET_COLOR="green"
          
          if [ "$CURRENT_COLOR" = "green" ]; then
            TARGET_COLOR="blue"
          fi
          
          echo "current-color=$CURRENT_COLOR" >> $GITHUB_OUTPUT
          echo "target-color=$TARGET_COLOR" >> $GITHUB_OUTPUT
          
          echo "Current active deployment: $CURRENT_COLOR"
          echo "Target deployment color: $TARGET_COLOR"

      - name: Validate image exists
        run: |
          # Check if the specified image tag exists in ECR
          IMAGE_URI="${{ secrets.ECR_REPOSITORY_URI }}:${{ inputs.image_tag }}"
          
          if aws ecr describe-images --repository-name $(echo ${{ secrets.ECR_REPOSITORY_URI }} | cut -d'/' -f2) --image-ids imageTag=${{ inputs.image_tag }} >/dev/null 2>&1; then
            echo "✅ Image $IMAGE_URI exists"
          else
            echo "❌ Image $IMAGE_URI not found"
            exit 1
          fi

  blue-green-deployment:
    name: Blue/Green Deployment
    runs-on: ubuntu-latest
    needs: pre-deployment-checks
    if: inputs.deployment_type == 'blue-green' && !inputs.rollback
    environment: ${{ inputs.environment }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
          role-to-assume: ${{ secrets.AWS_DEPLOYMENT_ROLE_ARN }}
          role-duration-seconds: 3600

      - name: Setup tools
        run: |
          # Setup kubectl
          curl -LO "https://dl.k8s.io/release/v${{ env.KUBECTL_VERSION }}/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/
          
          # Setup Helm
          curl https://get.helm.sh/helm-v${{ env.HELM_VERSION }}-linux-amd64.tar.gz | tar xz
          sudo mv linux-amd64/helm /usr/local/bin/
          
          # Update kubeconfig
          aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ needs.pre-deployment-checks.outputs.cluster-name }}

      - name: Deploy to target environment
        env:
          TARGET_COLOR: ${{ needs.pre-deployment-checks.outputs.target-color }}
          IMAGE_TAG: ${{ inputs.image_tag }}
          ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY_URI }}
        run: |
          echo "Deploying $TARGET_COLOR environment with image tag: $IMAGE_TAG"
          
          # Create namespace if it doesn't exist
          kubectl create namespace pyairtable-${{ inputs.environment }} --dry-run=client -o yaml | kubectl apply -f -
          
          # Deploy the new version to the target color environment
          envsubst < k8s/deployments/blue-green-deployment.yaml | kubectl apply -f -
          
          # Wait for deployment to be ready
          kubectl rollout status deployment/pyairtable-app-${TARGET_COLOR} -n pyairtable-${{ inputs.environment }} --timeout=600s

      - name: Run health checks
        env:
          TARGET_COLOR: ${{ needs.pre-deployment-checks.outputs.target-color }}
        run: |
          echo "Running health checks on $TARGET_COLOR deployment..."
          
          # Wait for pods to be ready
          kubectl wait --for=condition=ready pod -l app=pyairtable-app,color=$TARGET_COLOR -n pyairtable-${{ inputs.environment }} --timeout=300s
          
          # Port forward for testing
          kubectl port-forward service/pyairtable-app-${TARGET_COLOR}-service 8080:80 -n pyairtable-${{ inputs.environment }} &
          PF_PID=$!
          
          # Wait a moment for port forward to establish
          sleep 5
          
          # Run health check
          for i in {1..10}; do
            if curl -f http://localhost:8080/health >/dev/null 2>&1; then
              echo "✅ Health check passed on attempt $i"
              break
            else
              echo "⏳ Health check failed on attempt $i, retrying..."
              sleep 10
            fi
            
            if [ $i -eq 10 ]; then
              echo "❌ Health checks failed after 10 attempts"
              kill $PF_PID
              exit 1
            fi
          done
          
          # Cleanup
          kill $PF_PID

      - name: Run integration tests
        env:
          TARGET_COLOR: ${{ needs.pre-deployment-checks.outputs.target-color }}
        run: |
          echo "Running integration tests against $TARGET_COLOR deployment..."
          
          # Port forward for testing
          kubectl port-forward service/pyairtable-app-${TARGET_COLOR}-service 8080:80 -n pyairtable-${{ inputs.environment }} &
          PF_PID=$!
          
          sleep 5
          
          # Run integration tests
          if [ -f "tests/integration/run-tests.sh" ]; then
            cd tests/integration
            export TEST_BASE_URL="http://localhost:8080"
            ./run-tests.sh
          else
            echo "No integration tests found, skipping..."
          fi
          
          # Cleanup
          kill $PF_PID

      - name: Switch traffic to new deployment
        env:
          TARGET_COLOR: ${{ needs.pre-deployment-checks.outputs.target-color }}
          CURRENT_COLOR: ${{ needs.pre-deployment-checks.outputs.current-color }}
        run: |
          echo "Switching traffic from $CURRENT_COLOR to $TARGET_COLOR..."
          
          # Update the main service to point to the new deployment
          kubectl patch service pyairtable-app-service -n pyairtable-${{ inputs.environment }} -p '{"spec":{"selector":{"color":"'$TARGET_COLOR'"}}}'
          
          # Wait a moment for the service to update
          sleep 10
          
          echo "✅ Traffic successfully switched to $TARGET_COLOR deployment"

      - name: Verify traffic switch
        env:
          TARGET_COLOR: ${{ needs.pre-deployment-checks.outputs.target-color }}
        run: |
          echo "Verifying traffic is routing to $TARGET_COLOR deployment..."
          
          # Get the load balancer URL
          LB_URL=$(kubectl get service pyairtable-app-service -n pyairtable-${{ inputs.environment }} -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          
          if [ -n "$LB_URL" ]; then
            for i in {1..5}; do
              RESPONSE=$(curl -s http://$LB_URL/health | jq -r '.deployment_color // "unknown"')
              if [ "$RESPONSE" = "$TARGET_COLOR" ]; then
                echo "✅ Traffic verification successful - response from $TARGET_COLOR"
                break
              else
                echo "⏳ Traffic verification attempt $i - got response from $RESPONSE, expected $TARGET_COLOR"
                sleep 10
              fi
              
              if [ $i -eq 5 ]; then
                echo "❌ Traffic verification failed after 5 attempts"
                exit 1
              fi
            done
          else
            echo "⚠️ No load balancer found, skipping external traffic verification"
          fi

      - name: Clean up old deployment
        env:
          CURRENT_COLOR: ${{ needs.pre-deployment-checks.outputs.current-color }}
          TARGET_COLOR: ${{ needs.pre-deployment-checks.outputs.target-color }}
        run: |
          echo "Keeping $CURRENT_COLOR deployment for potential rollback..."
          echo "Old deployment will be cleaned up in the next deployment cycle"
          
          # Optionally scale down the old deployment to save resources
          if [ "${{ inputs.environment }}" != "production" ]; then
            kubectl scale deployment pyairtable-app-${CURRENT_COLOR} --replicas=1 -n pyairtable-${{ inputs.environment }}
            echo "Scaled down $CURRENT_COLOR deployment to 1 replica for cost optimization"
          fi

  canary-deployment:
    name: Canary Deployment
    runs-on: ubuntu-latest
    needs: pre-deployment-checks
    if: inputs.deployment_type == 'canary' && !inputs.rollback
    environment: ${{ inputs.environment }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
          role-to-assume: ${{ secrets.AWS_DEPLOYMENT_ROLE_ARN }}
          role-duration-seconds: 3600

      - name: Setup tools
        run: |
          curl -LO "https://dl.k8s.io/release/v${{ env.KUBECTL_VERSION }}/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/
          
          aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ needs.pre-deployment-checks.outputs.cluster-name }}

      - name: Deploy canary version
        run: |
          echo "Deploying canary version with 10% traffic..."
          
          # Deploy canary with 10% of traffic
          kubectl apply -f - <<EOF
          apiVersion: argoproj.io/v1alpha1
          kind: Rollout
          metadata:
            name: pyairtable-app-rollout
            namespace: pyairtable-${{ inputs.environment }}
          spec:
            replicas: 5
            strategy:
              canary:
                steps:
                - setWeight: 10
                - pause: {duration: 2m}
                - setWeight: 30
                - pause: {duration: 2m}
                - setWeight: 50
                - pause: {duration: 2m}
                - setWeight: 100
            selector:
              matchLabels:
                app: pyairtable-app
            template:
              metadata:
                labels:
                  app: pyairtable-app
              spec:
                containers:
                - name: app
                  image: ${{ secrets.ECR_REPOSITORY_URI }}:${{ inputs.image_tag }}
                  ports:
                  - containerPort: 8080
          EOF

      - name: Monitor canary deployment
        run: |
          echo "Monitoring canary deployment progress..."
          kubectl argo rollouts get rollout pyairtable-app-rollout -n pyairtable-${{ inputs.environment }} --watch

  rollback-deployment:
    name: Rollback Deployment
    runs-on: ubuntu-latest
    needs: pre-deployment-checks
    if: inputs.rollback
    environment: ${{ inputs.environment }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
          role-to-assume: ${{ secrets.AWS_DEPLOYMENT_ROLE_ARN }}
          role-duration-seconds: 3600

      - name: Setup kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/v${{ env.KUBECTL_VERSION }}/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/
          
          aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ needs.pre-deployment-checks.outputs.cluster-name }}

      - name: Rollback to previous version
        env:
          CURRENT_COLOR: ${{ needs.pre-deployment-checks.outputs.current-color }}
          TARGET_COLOR: ${{ needs.pre-deployment-checks.outputs.target-color }}
        run: |
          echo "Rolling back from $CURRENT_COLOR to $TARGET_COLOR..."
          
          # Switch traffic back to the previous deployment
          kubectl patch service pyairtable-app-service -n pyairtable-${{ inputs.environment }} -p '{"spec":{"selector":{"color":"'$TARGET_COLOR'"}}}'
          
          echo "✅ Rollback completed - traffic switched back to $TARGET_COLOR"

      - name: Verify rollback
        env:
          TARGET_COLOR: ${{ needs.pre-deployment-checks.outputs.target-color }}
        run: |
          echo "Verifying rollback..."
          
          # Wait for service to update
          sleep 15
          
          # Get the load balancer URL and verify
          LB_URL=$(kubectl get service pyairtable-app-service -n pyairtable-${{ inputs.environment }} -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          
          if [ -n "$LB_URL" ]; then
            RESPONSE=$(curl -s http://$LB_URL/health | jq -r '.deployment_color // "unknown"')
            if [ "$RESPONSE" = "$TARGET_COLOR" ]; then
              echo "✅ Rollback verification successful"
            else
              echo "❌ Rollback verification failed"
              exit 1
            fi
          fi

  notification:
    name: Send Notifications
    runs-on: ubuntu-latest
    needs: [pre-deployment-checks, blue-green-deployment, canary-deployment, rollback-deployment]
    if: always()
    
    steps:
      - name: Send Slack notification
        if: always()
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          channel: '#deployments'
          text: |
            🚀 Deployment Status: ${{ job.status }}
            
            **Environment:** ${{ inputs.environment }}
            **Strategy:** ${{ inputs.deployment_type }}
            **Image Tag:** ${{ inputs.image_tag }}
            **Rollback:** ${{ inputs.rollback }}
            
            **Workflow:** ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}