# Disaster Recovery and Backup Configuration for PyAirtable
---
# Namespace for backup operations
apiVersion: v1
kind: Namespace
metadata:
  name: backup
  labels:
    name: backup

---
# PostgreSQL Backup CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: postgres-backup
  namespace: backup
spec:
  schedule: "0 2 * * *"  # Daily at 2 AM
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: backup-sa
          containers:
          - name: postgres-backup
            image: postgres:15-alpine
            command:
            - /bin/bash
            - -c
            - |
              set -e
              BACKUP_NAME="pyairtable-backup-$(date +%Y%m%d-%H%M%S)"
              
              # Create backup
              PGPASSWORD=$POSTGRES_PASSWORD pg_dump \
                -h postgres-service.pyairtable.svc.cluster.local \
                -U $POSTGRES_USER \
                -d $POSTGRES_DB \
                --clean \
                --create \
                --verbose \
                > /backup/${BACKUP_NAME}.sql
              
              # Compress backup
              gzip /backup/${BACKUP_NAME}.sql
              
              # Create metadata
              cat > /backup/${BACKUP_NAME}.metadata << EOF
              backup_name: ${BACKUP_NAME}
              database: ${POSTGRES_DB}
              timestamp: $(date -Iseconds)
              size: $(stat -c%s /backup/${BACKUP_NAME}.sql.gz)
              checksum: $(md5sum /backup/${BACKUP_NAME}.sql.gz | cut -d' ' -f1)
              EOF
              
              # Cleanup old backups (keep last 7 days)
              find /backup -name "*.sql.gz" -mtime +7 -delete
              find /backup -name "*.metadata" -mtime +7 -delete
              
              echo "Backup completed: ${BACKUP_NAME}.sql.gz"
            env:
            - name: POSTGRES_USER
              valueFrom:
                secretKeyRef:
                  name: pyairtable-secrets
                  key: postgres-user
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: pyairtable-secrets
                  key: postgres-password
            - name: POSTGRES_DB
              valueFrom:
                secretKeyRef:
                  name: pyairtable-secrets
                  key: postgres-db
            volumeMounts:
            - name: backup-storage
              mountPath: /backup
            resources:
              requests:
                memory: "256Mi"
                cpu: "100m"
              limits:
                memory: "512Mi"
                cpu: "200m"
          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: postgres-backup-pvc
          restartPolicy: OnFailure

---
# Redis Backup CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: redis-backup
  namespace: backup
spec:
  schedule: "30 2 * * *"  # Daily at 2:30 AM
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: backup-sa
          containers:
          - name: redis-backup
            image: redis:7.4-alpine
            command:
            - /bin/sh
            - -c
            - |
              set -e
              BACKUP_NAME="redis-backup-$(date +%Y%m%d-%H%M%S)"
              
              # Create Redis backup using BGSAVE
              redis-cli -h redis-service.pyairtable.svc.cluster.local -p 6379 -a $REDIS_PASSWORD BGSAVE
              
              # Wait for backup to complete
              while [ "$(redis-cli -h redis-service.pyairtable.svc.cluster.local -p 6379 -a $REDIS_PASSWORD LASTSAVE)" = "$(redis-cli -h redis-service.pyairtable.svc.cluster.local -p 6379 -a $REDIS_PASSWORD LASTSAVE)" ]; do
                sleep 5
              done
              
              # Copy RDB file (this would need to be adapted for actual Redis data volume)
              echo "Redis backup completed at $(date)"
              
              # Create metadata
              cat > /backup/${BACKUP_NAME}.metadata << EOF
              backup_name: ${BACKUP_NAME}
              service: redis
              timestamp: $(date -Iseconds)
              EOF
              
              # Cleanup old backups
              find /backup -name "redis-backup-*.metadata" -mtime +7 -delete
            env:
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: pyairtable-secrets
                  key: redis-password
            volumeMounts:
            - name: backup-storage
              mountPath: /backup
            resources:
              requests:
                memory: "128Mi"
                cpu: "50m"
              limits:
                memory: "256Mi"
                cpu: "100m"
          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: redis-backup-pvc
          restartPolicy: OnFailure

---
# Service Configuration Backup CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: k8s-config-backup
  namespace: backup
spec:
  schedule: "0 3 * * *"  # Daily at 3 AM
  concurrencyPolicy: Forbid
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: backup-sa
          containers:
          - name: k8s-backup
            image: bitnami/kubectl:latest
            command:
            - /bin/bash
            - -c
            - |
              set -e
              BACKUP_NAME="k8s-config-backup-$(date +%Y%m%d-%H%M%S)"
              mkdir -p /backup/${BACKUP_NAME}
              
              # Backup PyAirtable namespace resources
              kubectl get all -n pyairtable -o yaml > /backup/${BACKUP_NAME}/pyairtable-resources.yaml
              kubectl get configmaps -n pyairtable -o yaml > /backup/${BACKUP_NAME}/pyairtable-configmaps.yaml
              kubectl get secrets -n pyairtable -o yaml > /backup/${BACKUP_NAME}/pyairtable-secrets.yaml
              kubectl get pvc -n pyairtable -o yaml > /backup/${BACKUP_NAME}/pyairtable-pvcs.yaml
              
              # Backup observability namespace
              kubectl get all -n observability -o yaml > /backup/${BACKUP_NAME}/observability-resources.yaml
              
              # Backup Istio configurations
              kubectl get gateway,virtualservice,destinationrule -n pyairtable -o yaml > /backup/${BACKUP_NAME}/istio-configs.yaml
              
              # Create archive
              tar czf /backup/${BACKUP_NAME}.tar.gz -C /backup ${BACKUP_NAME}
              rm -rf /backup/${BACKUP_NAME}
              
              # Cleanup old backups
              find /backup -name "k8s-config-backup-*.tar.gz" -mtime +30 -delete
              
              echo "Kubernetes config backup completed: ${BACKUP_NAME}.tar.gz"
            volumeMounts:
            - name: backup-storage
              mountPath: /backup
            resources:
              requests:
                memory: "256Mi"
                cpu: "100m"
              limits:
                memory: "512Mi"
                cpu: "200m"
          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: k8s-backup-pvc
          restartPolicy: OnFailure

---
# Disaster Recovery Job Template
apiVersion: batch/v1
kind: Job
metadata:
  name: disaster-recovery-template
  namespace: backup
  labels:
    job-type: disaster-recovery
spec:
  template:
    spec:
      serviceAccountName: backup-sa
      containers:
      - name: disaster-recovery
        image: postgres:15-alpine
        command:
        - /bin/bash
        - -c
        - |
          set -e
          
          # Check if this is a recovery operation
          if [ "$RECOVERY_MODE" = "true" ]; then
            echo "Starting disaster recovery process..."
            
            # Wait for database to be ready
            until pg_isready -h postgres-service.pyairtable.svc.cluster.local -U $POSTGRES_USER; do
              echo "Waiting for PostgreSQL..."
              sleep 5
            done
            
            # Find latest backup
            LATEST_BACKUP=$(ls -t /backup/pyairtable-backup-*.sql.gz | head -1)
            
            if [ -z "$LATEST_BACKUP" ]; then
              echo "No backup files found!"
              exit 1
            fi
            
            echo "Restoring from backup: $LATEST_BACKUP"
            
            # Restore database
            gunzip -c $LATEST_BACKUP | PGPASSWORD=$POSTGRES_PASSWORD psql \
              -h postgres-service.pyairtable.svc.cluster.local \
              -U $POSTGRES_USER
            
            echo "Database restoration completed"
            
            # Verify restoration
            TABLE_COUNT=$(PGPASSWORD=$POSTGRES_PASSWORD psql \
              -h postgres-service.pyairtable.svc.cluster.local \
              -U $POSTGRES_USER \
              -d $POSTGRES_DB \
              -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public';")
            
            echo "Restored database contains $TABLE_COUNT tables"
          else
            echo "Disaster recovery job template - set RECOVERY_MODE=true to run actual recovery"
          fi
        env:
        - name: RECOVERY_MODE
          value: "false"  # Set to "true" to trigger actual recovery
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: pyairtable-secrets
              key: postgres-user
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: pyairtable-secrets
              key: postgres-password
        - name: POSTGRES_DB
          valueFrom:
            secretKeyRef:
              name: pyairtable-secrets
              key: postgres-db
        volumeMounts:
        - name: backup-storage
          mountPath: /backup
        resources:
          requests:
            memory: "512Mi"
            cpu: "200m"
          limits:
            memory: "1Gi"
            cpu: "500m"
      volumes:
      - name: backup-storage
        persistentVolumeClaim:
          claimName: postgres-backup-pvc
      restartPolicy: OnFailure

---
# Backup Storage PVCs
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-backup-pvc
  namespace: backup
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  storageClassName: fast-ssd

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: redis-backup-pvc
  namespace: backup
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: fast-ssd

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: k8s-backup-pvc
  namespace: backup
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
  storageClassName: fast-ssd

---
# Service Account for backup operations
apiVersion: v1
kind: ServiceAccount
metadata:
  name: backup-sa
  namespace: backup

---
# RBAC for backup service account
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: backup-role
rules:
- apiGroups: [""]
  resources: ["pods", "services", "configmaps", "secrets", "persistentvolumeclaims"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["apps"]
  resources: ["deployments", "statefulsets", "replicasets"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["networking.istio.io"]
  resources: ["gateways", "virtualservices", "destinationrules"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["batch"]
  resources: ["jobs", "cronjobs"]
  verbs: ["get", "list", "create", "update", "patch", "delete"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: backup-role-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: backup-role
subjects:
- kind: ServiceAccount
  name: backup-sa
  namespace: backup

---
# Emergency Rollback Script ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: emergency-scripts
  namespace: backup
data:
  emergency-rollback.sh: |
    #!/bin/bash
    set -e
    
    echo "=== Emergency Rollback Procedure ==="
    echo "This script will rollback PyAirtable to the last known good state"
    
    # Check if we have backups
    if [ ! -d "/backup" ]; then
      echo "ERROR: Backup directory not found!"
      exit 1
    fi
    
    # Find latest backup
    LATEST_DB_BACKUP=$(ls -t /backup/pyairtable-backup-*.sql.gz 2>/dev/null | head -1)
    LATEST_CONFIG_BACKUP=$(ls -t /backup/k8s-config-backup-*.tar.gz 2>/dev/null | head -1)
    
    if [ -z "$LATEST_DB_BACKUP" ]; then
      echo "ERROR: No database backup found!"
      exit 1
    fi
    
    echo "Latest database backup: $LATEST_DB_BACKUP"
    echo "Latest config backup: $LATEST_CONFIG_BACKUP"
    
    # Scale down services
    echo "Scaling down services..."
    kubectl scale deployment --all --replicas=0 -n pyairtable
    
    # Wait for pods to terminate
    echo "Waiting for pods to terminate..."
    kubectl wait --for=delete pod --all -n pyairtable --timeout=300s
    
    # Restore database
    echo "Restoring database..."
    # Database restoration would be handled by the disaster recovery job
    
    # Scale up services
    echo "Scaling up services..."
    kubectl scale deployment api-gateway --replicas=3 -n pyairtable
    kubectl scale deployment airtable-gateway --replicas=2 -n pyairtable
    kubectl scale deployment llm-orchestrator --replicas=2 -n pyairtable
    kubectl scale deployment mcp-server --replicas=2 -n pyairtable
    
    # Wait for services to be ready
    echo "Waiting for services to be ready..."
    kubectl wait --for=condition=available --timeout=600s deployment --all -n pyairtable
    
    echo "=== Rollback completed ==="
    echo "Please verify system functionality before resuming operations"
  
  health-check.sh: |
    #!/bin/bash
    # Health check script for disaster recovery validation
    
    echo "=== Post-Recovery Health Check ==="
    
    # Check pod status
    echo "Checking pod status..."
    kubectl get pods -n pyairtable
    
    # Check service endpoints
    echo "Checking service endpoints..."
    kubectl get endpoints -n pyairtable
    
    # Test API Gateway
    echo "Testing API Gateway..."
    if curl -f -s http://api-gateway.pyairtable.svc.cluster.local:8080/api/health > /dev/null; then
      echo "✓ API Gateway is responding"
    else
      echo "✗ API Gateway health check failed"
    fi
    
    # Test database connectivity
    echo "Testing database connectivity..."
    if kubectl exec -n pyairtable deployment/postgres -- pg_isready > /dev/null; then
      echo "✓ PostgreSQL is responding"
    else
      echo "✗ PostgreSQL health check failed"
    fi
    
    # Test Redis connectivity
    echo "Testing Redis connectivity..."
    if kubectl exec -n pyairtable deployment/redis -- redis-cli ping > /dev/null; then
      echo "✓ Redis is responding"
    else
      echo "✗ Redis health check failed"
    fi
    
    echo "=== Health Check Complete ==="

---
# Monitoring for backup jobs
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: backup-jobs-monitor
  namespace: backup
  labels:
    app: backup-jobs
spec:
  selector:
    matchLabels:
      job-type: backup
  endpoints:
  - port: metrics
    interval: 60s
    path: /metrics